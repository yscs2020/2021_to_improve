{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be6f4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1 2\n",
      "2 3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "meeting = {}\n",
    "nums = int(input())\n",
    "for i in range(nums):\n",
    "    n = int(input())\n",
    "    list_n  = []\n",
    "    for j in range(n):\n",
    "        info_time = input()\n",
    "        a,b = int(info_time.split(' ')[0]),int(info_time.split(' ')[1])\n",
    "        list_n.append([a,b])\n",
    "    meeting[i] = list_n\n",
    "\n",
    "for i in meeting.keys():\n",
    "    data = meeting[i]\n",
    "    data = sorted(data,key = lambda x: (x[0],x[1]))\n",
    "    start = data[0][0]\n",
    "    end = data[1][1]\n",
    "    result  = end - start\n",
    "    for j in data[1:]:\n",
    "        if j[0]>end:\n",
    "            start = j[0]\n",
    "            end = j[1]\n",
    "            result  += (end - start) \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4306b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [(12,12),(13,13),(14,12),(12,34),(13,22),(13,64)]\n",
    "L.sort(key=lambda x:(x[0],-x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7294a9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 1 1 1 0]\n",
      " [1 1 1 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "verctor = CountVectorizer()\n",
    "res = verctor.fit_transform(['lift is short i love python','lift is too long,I have python'])\n",
    "print(res.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a809170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "alist = [{'city':'Beijing','temp':33},\n",
    "         {'city':'GZ','temp':42},\n",
    "         {'city':'SH','temp':40}]\n",
    "d = DictVectorizer()\n",
    "feature = d.fit_transform(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6047aa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 3)\t33.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 3)\t42.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 3)\t40.0\n"
     ]
    }
   ],
   "source": [
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e2a2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. 33.]\n",
      " [ 0.  1.  0. 42.]\n",
      " [ 0.  0.  1. 40.]]\n",
      "['city=Beijing', 'city=GZ', 'city=SH', 'temp']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "alist = [{'city':'Beijing','temp':33},\n",
    "         {'city':'GZ','temp':42},\n",
    "         {'city':'SH','temp':40}]\n",
    "d = DictVectorizer(sparse=False)\n",
    "feature = d.fit_transform(alist)\n",
    "print(feature)\n",
    "print(d.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d37d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    ['green','M',20,'class1'],\n",
    "    ['red','L',21,'class2'],\n",
    "    ['blue','XL',30,'class3'],\n",
    "])\n",
    "df.columns=['color','size','weight','class Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecab6377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>weight</th>\n",
       "      <th>class Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>21</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>30</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  weight class Label\n",
       "0  green    M      20      class1\n",
       "1    red    L      21      class2\n",
       "2   blue   XL      30      class3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e1958bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blue  green  red\n",
       "0     0      1    0\n",
       "1     0      0    1\n",
       "2     1      0    0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7f0450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. 33.]\n",
      " [ 0.  1.  0. 42.]\n",
      " [ 0.  0.  1. 40.]]\n",
      "['city=Beijing', 'city=GZ', 'city=SH', 'temp']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "alist = [{'city':'Beijing','temp':33},\n",
    "         {'city':'GZ','temp':42},\n",
    "         {'city':'SH','temp':40}]\n",
    "d = DictVectorizer(sparse=False)\n",
    "feature = d.fit_transform(alist)\n",
    "print(feature)\n",
    "print(d.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b1f8063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vector = CountVectorizer()\n",
    "res = vector.fit_transform(['lift is short, I love python','left is too long,I have python'])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de1a7489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 0, 1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdae2496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have', 'is', 'left', 'lift', 'long', 'love', 'python', 'short', 'too']\n"
     ]
    }
   ],
   "source": [
    "print(vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daf5be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "res_cn = vector.fit_transform(['人生苦短，我用Python','人生漫长，不用python'])\n",
    "print(res_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9e2faff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不用python', '人生漫长', '人生苦短', '我用python']\n",
      "[[0 0 1 1]\n",
      " [1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vector.get_feature_names())\n",
    "print(res_cn.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40bc98cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '是', '一个', '好人']\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jb = jieba.cut('我是一个好人')\n",
    "content = list(jb)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37dc294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我 是 一个 好人'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = ' '.join(content)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3bf5ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "jb1 = jieba.cut('人生苦短，我用Python，你觉得我说的对吗？')\n",
    "ct1 = ' '.join(list(jb1))\n",
    "jb2 = jieba.cut('人生苦短，我用Python，你觉得我说的对不对？')\n",
    "ct2 = ' '.join(list(jb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de967c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人生 苦短 ， 我用 Python ， 你 觉得 我 说 的 对 吗 ？ 人生 苦短 ， 我用 Python ， 你 觉得 我 说 的 对 不 对 ？\n"
     ]
    }
   ],
   "source": [
    "print(ct1,ct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33d77cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4)\t1\n",
      "['python', '人生', '我用', '苦短', '觉得']\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "verctor = CountVectorizer()\n",
    "res = verctor.fit_transform([ct1,ct2])\n",
    "print(res)\n",
    "print(verctor.get_feature_names())\n",
    "print(res.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19267b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 1.        , 1.        ],\n",
       "       [0.43333333, 0.33333333, 0.6       , 1.        ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler(feature_range=(0,1))\n",
    "data = [[90,2,10,4],[60,5,15,45],[73,3,13,45]]\n",
    "data = mm.fit_transform(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a56c6e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27540458, -1.06904497, -1.29777137, -1.41421356],\n",
       "       [-1.16685951,  1.33630621,  1.13554995,  0.70710678],\n",
       "       [-0.10854507, -0.26726124,  0.16222142,  0.70710678]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "mm = StandardScaler()\n",
    "data = [[90,2,10,4],[60,5,15,45],[73,3,13,45]]\n",
    "data = mm.fit_transform(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b03239ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [3],\n",
       "       [9]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "v = VarianceThreshold(threshold=3)\n",
    "v.fit_transform([[0,2,4,3],[0,3,7,3],[0,9,6,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "389d0b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97, 12, 67, 51, 78, 39, 96, 14, 36, 68],\n",
       "       [13, 62, 20, 23, 49, 67, 14, 91, 44, 44],\n",
       "       [98, 60, 91, 86, 86, 92, 57, 71, 66, 39],\n",
       "       [73, 65, 64, 40, 60, 62, 49, 77,  3, 77],\n",
       "       [53, 55, 80, 57, 71, 52, 12, 46, 17, 22]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "feature = np.random.randint(0,100,size=(5,10))\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa841eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.median(feature.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e407f58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97, 67, 96, 14, 36],\n",
       "       [13, 20, 14, 91, 44],\n",
       "       [98, 91, 57, 71, 66],\n",
       "       [73, 64, 49, 77,  3],\n",
       "       [53, 80, 12, 46, 17]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = VarianceThreshold(threshold=mean)\n",
    "v.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d8358a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.89907883e+00, -1.26306846e+00,  1.34020526e-16],\n",
       "       [-1.48739895e+00,  1.56662409e+00,  1.34020526e-16],\n",
       "       [ 4.38647778e+00, -3.03555627e-01,  1.34020526e-16]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit_transform([[0,2,4,3],[0,3,7,3],[0,9,6,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4449697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.49291005e+01, 2.07089949e+00, 2.69422521e-32])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "212d4abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.78182383e-01, 1.21817617e-01, 1.58483836e-33])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e395e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.93371683e-31, -1.63741677e-15, -1.25698241e-16,\n",
       "        -2.51923793e-16],\n",
       "       [-1.63741677e-15,  1.43333333e+01,  1.83333333e+00,\n",
       "         2.16666667e+00],\n",
       "       [-1.25698241e-16,  1.83333333e+00,  2.33333333e+00,\n",
       "         1.66666667e-01],\n",
       "       [-2.51923793e-16,  2.16666667e+00,  1.66666667e-01,\n",
       "         3.33333333e-01]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.get_covariance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d16992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "iris =datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e23e63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/Users/yanshuo/opt/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "733f1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = iris['data']\n",
    "target = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5899efbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape,target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf9e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.fetch_20newsgroups(data_home=None,subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "170331d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(feature,target,test_size=0.2,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22faede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
